import os
import google.generativeai as genai
from dotenv import load_dotenv
import logging # ë¡œê¹… ì¶”ê°€

# ë¡œê¹… ê¸°ë³¸ ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(name)s - %(message)s')

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
logging.info(".env íŒŒì¼ ë¡œë“œ ì‹œë„ ì™„ë£Œ.")

# í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©í•  ëª¨ë¸
# ì´ì „ í…ŒìŠ¤íŠ¸ì—ì„œ gemini-2.0-flashê°€ ì„±ê³µí–ˆìœ¼ë¯€ë¡œ í•´ë‹¹ ëª¨ë¸ ì‚¬ìš©
TEST_MODEL_NAME = "gemini-2.0-flash"

def check_google_api_key():
    """
    GOOGLE_API_KEYë¥¼ ì‚¬ìš©í•˜ì—¬ Gemini APIì— ê°„ë‹¨í•œ ìš”ì²­ì„ ë³´ë‚´ ìœ íš¨ì„±ì„ ê²€ì‚¬í•˜ê³ ,
    ì‘ë‹µì˜ finish_reason ë° safety_ratingsë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    logging.info("ğŸ” Google API í‚¤ ìœ íš¨ì„± ê²€ì‚¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

    api_key = os.getenv("GOOGLE_API_KEY")

    if not api_key or api_key == "YOUR_ACTUAL_API_KEY" or api_key == "YOUR_API_KEY":
        logging.error("âŒ ì˜¤ë¥˜: GOOGLE_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šì€ ê°’ì…ë‹ˆë‹¤.")
        logging.error("   '.env' íŒŒì¼ì„ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ë§Œë“¤ê³  GOOGLE_API_KEY=\"ì‹¤ì œAPIí‚¤\" í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return

    logging.info(f"ğŸ”‘ API í‚¤ ë¡œë“œë¨ (ì¼ë¶€ë§Œ í‘œì‹œ): {api_key[:5]}...{api_key[-5:]}")

    try:
        # API í‚¤ ì„¤ì •
        genai.configure(api_key=api_key)
        logging.info(f"âœ… genai.configure(api_key=...) ì„±ê³µ.")

        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ë””ë²„ê¹… ì‹œ ì£¼ì„ í•´ì œ)
        # logging.info("\nğŸ”„ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        # model_count = 0
        # models_found = []
        # for m in genai.list_models():
        #     if 'generateContent' in m.supported_generation_methods:
        #         logging.debug(f"  - ëª¨ë¸ëª…: {m.name}, ì§€ì› ë©”ì„œë“œ: {m.supported_generation_methods}")
        #         models_found.append(m.name)
        #         model_count +=1
        # if model_count > 0:
        #     logging.info(f"âœ… {model_count}ê°œì˜ ì‚¬ìš© ê°€ëŠ¥í•œ (generateContent ì§€ì›) ëª¨ë¸ ì •ë³´ë¥¼ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
        #     logging.info(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤: {models_found}")
        # else:
        #     logging.warning("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ (generateContent ì§€ì›) ëª¨ë¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")


        # í…ŒìŠ¤íŠ¸ ëª¨ë¸ ê°ì²´ ìƒì„±
        logging.info(f"\nğŸ”„ í…ŒìŠ¤íŠ¸ ëª¨ë¸ '{TEST_MODEL_NAME}' ê°ì²´ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘...")
        model = genai.GenerativeModel(TEST_MODEL_NAME)
        logging.info(f"âœ… ëª¨ë¸ '{TEST_MODEL_NAME}' ê°ì²´ ìƒì„± ì„±ê³µ.")

        # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ìƒì„± ìš”ì²­ ë³´ë‚´ê¸°
        prompt = "Hello! ì˜ì–´ë¡œ ë§¤ìš° ê°„ë‹¨í•œ ì¸ì‚¬ë§ í•˜ë‚˜ë§Œ ìƒì„±í•´ì£¼ì„¸ìš”." # í”„ë¡¬í”„íŠ¸ ê°„ì†Œí™”
        logging.info(f"\nğŸ“ í”„ë¡¬í”„íŠ¸: \"{prompt}\"")
        logging.info("â³ LLMì— ìš”ì²­ ì¤‘...")

        # ì‘ë‹µ ìƒì„±
        response = model.generate_content(prompt)
        logging.info("âœ… LLM ì‘ë‹µ ìˆ˜ì‹  ì„±ê³µ.")

        # ì‘ë‹µ í…ìŠ¤íŠ¸ ë° ìƒì„¸ ì •ë³´ ì¶œë ¥
        if response.text:
            print("\nğŸ¤– LLM ì‘ë‹µ ë‚´ìš©:") # printë¡œ ì‚¬ìš©ìì—ê²Œ ëª…í™•íˆ ë³´ì—¬ì£¼ê¸°
            print(response.text)
            logging.info(f"   ì‘ë‹µ í…ìŠ¤íŠ¸: {response.text}") # ë¡œê·¸ì—ë„ ë‚¨ê¸°ê¸°

            if response.candidates:
                candidate = response.candidates[0]
                logging.info(f"   Finish Reason: {candidate.finish_reason}")
                # safety_ratingsëŠ” ì—†ì„ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ í™•ì¸ í›„ ì¶œë ¥
                if hasattr(candidate, 'safety_ratings') and candidate.safety_ratings:
                    logging.info(f"   Safety Ratings: {candidate.safety_ratings}")
                else:
                    logging.info("   Safety Ratings: ì •ë³´ ì—†ìŒ ë˜ëŠ” í•´ë‹¹ ì—†ìŒ")
            else:
                logging.warning("   ì‘ë‹µì— candidates ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

            print("\nğŸ‰ API í‚¤ê°€ ìœ íš¨í•˜ê³ , LLM í˜¸ì¶œì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!") # printë¡œ ì‚¬ìš©ìì—ê²Œ ëª…í™•íˆ ë³´ì—¬ì£¼ê¸°
            logging.info("ğŸ‰ API í‚¤ê°€ ìœ íš¨í•˜ê³ , LLM í˜¸ì¶œì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

        else:
            logging.error("\nâŒ LLMìœ¼ë¡œë¶€í„° ì‘ë‹µì„ ë°›ì•˜ìœ¼ë‚˜, ì‘ë‹µ ë‚´ìš©(text)ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            logging.error("   ëª¨ë¸ì´ í•´ë‹¹ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•´ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆê±°ë‚˜, ì•ˆì „ í•„í„° ë“±ì— ì˜í•´ ì°¨ë‹¨ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            if hasattr(response, 'prompt_feedback') and response.prompt_feedback:
                logging.error(f"   í”„ë¡¬í”„íŠ¸ í”¼ë“œë°±: {response.prompt_feedback}")
            if response.candidates:
                candidate = response.candidates[0]
                logging.error(f"   ì¢…ë£Œ ì´ìœ  (text ì—†ìŒ): {candidate.finish_reason}")
                if hasattr(candidate, 'safety_ratings') and candidate.safety_ratings:
                    logging.error(f"   ì•ˆì „ ë“±ê¸‰ (text ì—†ìŒ): {candidate.safety_ratings}")
            else:
                logging.warning("   ì‘ë‹µì— candidates ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤ (text ì—†ìŒ).")


    except Exception as e:
        logging.error(f"\nâŒ API í‚¤ ìœ íš¨ì„± ê²€ì‚¬ ë˜ëŠ” LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__}", exc_info=True)
        logging.error("   API í‚¤, Google Cloud í”„ë¡œì íŠ¸ ì„¤ì •(API í™œì„±í™”, ê²°ì œ), ë„¤íŠ¸ì›Œí¬ ì—°ê²°, ëª¨ë¸ ì´ë¦„ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    check_google_api_key()