# simple_model_test.py

import google.generativeai as genai
import os
from dotenv import load_dotenv
import traceback # ìƒì„¸ ì˜¤ë¥˜ ì¶œë ¥ì„ ìœ„í•´ ì¶”ê°€

# --- ì„¤ì • ë¶€ë¶„ ---
# 1. í…ŒìŠ¤íŠ¸í•  "2.5 í”„ë¡œ" ëª¨ë¸ IDë¥¼ ì •í™•í•˜ê²Œ ì…ë ¥í•˜ì„¸ìš”.
#    (ì˜ˆ: "gemini-2.5-pro-preview-05-06" ë˜ëŠ” config/models.pyì— ì •ì˜ëœ ë‹¤ë¥¸ 2.5 í”„ë¡œ ëª¨ë¸ ID)
MODEL_ID_TO_TEST = "gemini-2.5-pro-exp-03-25"  # <--- ì—¬ê¸°ì— í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ ID ì…ë ¥

# 2. (ì„ íƒ ì‚¬í•­) í…ŒìŠ¤íŠ¸ìš© ê°„ë‹¨í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
#    ë¹„ì›Œë‘ê±°ë‚˜ ë§¤ìš° ê°„ë‹¨í•˜ê²Œ ì„¤ì •í•©ë‹ˆë‹¤.
SYSTEM_INSTRUCTION = "You are a helpful assistant."
# SYSTEM_INSTRUCTION = None # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì—†ì´ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´ ì´ ì¤„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.

# 3. í…ŒìŠ¤íŠ¸ìš© ê°„ë‹¨í•œ ì‚¬ìš©ì ì…ë ¥
USER_INPUT = 'ëª°ë¼ìš”' # ì´ì „ ë¡œê·¸ì—ì„œ ë¬¸ì œê°€ ë°œìƒí–ˆë˜ ì…ë ¥ê°’ ì‚¬ìš©
# USER_INPUT = "Tell me a short joke about a cat." # ë˜ëŠ” ë‹¤ë¥¸ ë§¤ìš° ê°„ë‹¨í•œ ì…ë ¥ìœ¼ë¡œ í…ŒìŠ¤íŠ¸

# 4. (ì„ íƒ ì‚¬í•­) í…ŒìŠ¤íŠ¸ìš© ê°„ë‹¨í•œ ìƒì„± ì„¤ì •
#    ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•˜ê±°ë‚˜, ë¬¸ì œê°€ ì˜ì‹¬ë˜ëŠ” íŠ¹ì • ì„¤ì •ì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
#    max_output_tokensëŠ” ì‘ë‹µ ì˜ë¦¼ í˜„ìƒ í™•ì¸ì„ ìœ„í•´ ì¶©ë¶„íˆ í¬ê²Œ ì„¤ì •í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
GENERATION_CONFIG = {
    "temperature": 0.7,
    "max_output_tokens": 2048, # ì‘ë‹µ ì˜ë¦¼ ë°©ì§€ë¥¼ ìœ„í•´ ì¶©ë¶„íˆ ì„¤ì •
    # "safety_settings": [...] # í•„ìš”í•œ ê²½ìš° ì•ˆì „ ì„¤ì • í…ŒìŠ¤íŠ¸ (ì´ì „ ë‹µë³€ ì°¸ê³ )
}
# GENERATION_CONFIG = None # ê¸°ë³¸ ìƒì„± ì„¤ì •ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì´ ì¤„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.
# --- ì„¤ì • ë¶€ë¶„ ë ---

def run_direct_model_test():
    """
    ì§€ì •ëœ ëª¨ë¸ IDë¡œ ì§ì ‘ API í˜¸ì¶œì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    print(f"--- ë…ë¦½ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘ ---")
    print(f"í…ŒìŠ¤íŠ¸ ëŒ€ìƒ ëª¨ë¸ ID: {MODEL_ID_TO_TEST}")

    # .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ (ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ ìœ„ì¹˜ ë˜ëŠ” PYTHONPATHì— .env íŒŒì¼ì´ ìˆì–´ì•¼ í•¨)
    load_dotenv()
    api_key = os.getenv("GOOGLE_API_KEY")

    if not api_key:
        print("ğŸ›‘ ì¤‘ìš”: GOOGLE_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   .env íŒŒì¼ì´ ì´ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ ìœ„ì¹˜ì— ìˆëŠ”ì§€, ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return

    print(f"ğŸ”‘ API í‚¤ ë¡œë“œ í™•ì¸ (ì• 5ìë¦¬): {api_key[:5]}...")
    genai.configure(api_key=api_key)

    try:
        print(f"\nğŸš€ ëª¨ë¸ ì´ˆê¸°í™” ì¤‘: {MODEL_ID_TO_TEST}")
        model_args = {"model_name": MODEL_ID_TO_TEST}
        if SYSTEM_INSTRUCTION:
            model_args["system_instruction"] = SYSTEM_INSTRUCTION
        
        model = genai.GenerativeModel(**model_args)

        print(f"ğŸ’¬ ì‚¬ìš©ì ì…ë ¥: '{USER_INPUT}'")
        
        request_args = {}
        if GENERATION_CONFIG:
            print(f"âš™ï¸ ìƒì„± ì„¤ì •: {GENERATION_CONFIG}")
            # google-generativeai 0.5.0 ì´ìƒ ë²„ì „ì—ì„œëŠ” GenerationConfig ê°ì²´ ì§ì ‘ ì „ë‹¬
            try:
                # types ëª¨ë“ˆì€ google.generativeai.types ë¡œ ì ‘ê·¼ ê°€ëŠ¥
                # í•˜ì§€ë§Œ ë³´í†µ GenerationConfigëŠ” genai.types.GenerationConfig ë¡œ ì§ì ‘ ì°¸ì¡° ê°€ëŠ¥
                # ë˜ëŠ” google.generativeai.types.GenerationConfig ë¡œë„ ê°€ëŠ¥
                request_args["generation_config"] = genai.types.GenerationConfig(**GENERATION_CONFIG)
            except AttributeError: # ì´ì „ ë²„ì „ í˜¸í™˜ì„± (genai.types.GenerationConfigê°€ ì—†ì„ ê²½ìš°)
                request_args["generation_config"] = GENERATION_CONFIG
                print("ì°¸ê³ : genai.types.GenerationConfig ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ dictë¡œ ì „ë‹¬í•©ë‹ˆë‹¤. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ì´ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        response = model.generate_content(
            USER_INPUT,
            **request_args
        )

        print("\n--- ì‘ë‹µ ê²°ê³¼ ---")
        if response.text:
            print(f"âœ… ì‘ë‹µ í…ìŠ¤íŠ¸:\n{response.text}")
        else:
            print("âš ï¸ LLMì´ ë¹ˆ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")

        # ìƒì„¸ ì‘ë‹µ ì •ë³´ ì¶œë ¥ (ë””ë²„ê¹…ì— ë§¤ìš° ì¤‘ìš”)
        print("\n--- ìƒì„¸ ì‘ë‹µ ì •ë³´ ---")
        if response.candidates:
            for i, candidate in enumerate(response.candidates):
                print(f"  í›„ë³´ {i+1}:")
                if hasattr(candidate, 'finish_reason'): # finish_reasonì´ í•­ìƒ ìˆëŠ”ì§€ í™•ì¸
                    print(f"    ì¢…ë£Œ ì´ìœ  (Finish Reason): {candidate.finish_reason}")
                    # finish_reasonì´ enumì¼ ê²½ìš° .nameìœ¼ë¡œ ì ‘ê·¼, ë¬¸ìì—´ì¼ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    finish_reason_name = candidate.finish_reason.name if hasattr(candidate.finish_reason, 'name') else str(candidate.finish_reason)
                    if finish_reason_name == "MAX_TOKENS":
                        print("    ğŸš¨ ê²½ê³ : max_output_tokens ì œí•œì— ë„ë‹¬í•˜ì—¬ ì‘ë‹µì´ ì˜ë ¸ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    elif finish_reason_name == "SAFETY":
                        print("    ğŸš¨ ê²½ê³ : ì•ˆì „ í•„í„°ì— ì˜í•´ ì‘ë‹µ ìƒì„±ì´ ì¤‘ë‹¨ë˜ì—ˆê±°ë‚˜ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    print("    ì¢…ë£Œ ì´ìœ  (Finish Reason) ì •ë³´ ì—†ìŒ.")
                
                if hasattr(candidate, 'safety_ratings') and candidate.safety_ratings:
                    print(f"    ì•ˆì „ ë“±ê¸‰ (Safety Ratings):")
                    for rating in candidate.safety_ratings:
                        print(f"      - ì¹´í…Œê³ ë¦¬: {rating.category}, í™•ë¥ : {rating.probability}")
                else:
                    print("    ì•ˆì „ ë“±ê¸‰ ì •ë³´ ì—†ìŒ.")
        else:
            print("  ì‘ë‹µì— í›„ë³´(candidates) ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

        if hasattr(response, 'prompt_feedback') and response.prompt_feedback:
            print(f"\n  í”„ë¡¬í”„íŠ¸ í”¼ë“œë°± (Prompt Feedback):")
            if hasattr(response.prompt_feedback, 'block_reason'):
                print(f"    ì°¨ë‹¨ ì´ìœ  (Block Reason): {response.prompt_feedback.block_reason}")
            if hasattr(response.prompt_feedback, 'block_reason_message') and response.prompt_feedback.block_reason_message:
                 print(f"    ì°¨ë‹¨ ì´ìœ  ë©”ì‹œì§€: {response.prompt_feedback.block_reason_message}")
            if hasattr(response.prompt_feedback, 'safety_ratings') and response.prompt_feedback.safety_ratings:
                print(f"    ì•ˆì „ ë“±ê¸‰ (Safety Ratings):")
                for rating in response.prompt_feedback.safety_ratings:
                    print(f"      - ì¹´í…Œê³ ë¦¬: {rating.category}, í™•ë¥ : {rating.probability}")
        else:
            print("\n  í”„ë¡¬í”„íŠ¸ í”¼ë“œë°± ì •ë³´ ì—†ìŒ.")
        
        # print(f"\n(ì°¸ê³ ìš© ì „ì²´ ì‘ë‹µ ê°ì²´: {response})") # í•„ìš”ì‹œ ì£¼ì„ í•´ì œ

    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__} - {e}")
        traceback.print_exc() # ìƒì„¸ ì˜¤ë¥˜ ìŠ¤íƒ ì¶œë ¥
    finally:
        print("\n--- ë…ë¦½ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì¢…ë£Œ ---")

if __name__ == "__main__":
    run_direct_model_test()